{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Local Prediction Rigidity analysis\n\n:Authors: Sanggyu \"Raymond\" Chong [@SanggyuChong](https://github.com/sanggyuChong/);\n          Federico Grasselli [@fgrassel](https://github.com/fgrassel/)\n\nIn this tutorial, we calculate the SOAP descriptors of an amorphous\nsilicon dataset using featomic, then compute the local prediction\nrigidity (LPR) for the atoms of a \"test\" set before and after\nmodifications to the \"training\" dataset has been made.\n\nFirst, we import all the necessary packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport tarfile\n\nimport numpy as np\nimport requests\nfrom ase.io import read\nfrom featomic import SoapPowerSpectrum\nfrom matplotlib import pyplot as plt\nfrom matplotlib.colors import LogNorm\nfrom sklearn.decomposition import PCA\nfrom skmatter.metrics import local_prediction_rigidity as lpr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load and prepare amorphous silicon data\n\n\nWe first download the dataset associated with LPR\nanalysis from Materials Cloud and load the the amorphous\nsilicon structures using [ASE](https://wiki.fysik.dtu.dk/ase/).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filename = \"LPR_supp_notebook_dataset.tar.gz\"\nif not os.path.exists(filename):\n    url = \"https://archive.materialscloud.org/records/1wsvs-sb736/files/LPR_supp_notebook_dataset.tar.gz\"  # noqa: E501\n    response = requests.get(url)\n    response.raise_for_status()\n    with open(filename, \"wb\") as f:\n        f.write(response.content)\n\nwith tarfile.open(filename) as tar:\n    tar.extractall(path=\".\")\n\nframes_pristine = read(\"datasets/Si_amo_defect_free.xyz\", \":\")\nframes_defect = read(\"datasets/Si_amo_defect_containing.xyz\", \":\")\n\n# Randomly shuffle the structures\n\nnp.random.seed(20230215)\n\nids = list(range(len(frames_pristine)))\nnp.random.shuffle(ids)\nframes_pristine = [frames_pristine[ii] for ii in ids]\n\nids = list(range(len(frames_defect)))\nnp.random.shuffle(ids)\nframes_defect = [frames_defect[ii] for ii in ids]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now further refine the loaded datasets according the the\nnumber of coordinated atoms that each atomic environment exhibits.\n\"Pristine\" refers to structures where all of the atoms have strictly\n4 coordinating atoms. \"Defect\" refers to structures that contain\natoms with coordination numbers other than 4.\n\nWe use :code:`get_all_distances` function of :code:`ase.Atoms` to detect the\nnumber of coordinated atoms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cur_cutoff = 2.7\nrefined_pristine_frames = []\nfor frame in frames_pristine:\n    neighs = (frame.get_all_distances(mic=True) < cur_cutoff).sum(axis=0) - 1\n    if neighs.max() > 4 or neighs.min() < 4:\n        continue\n    else:\n        refined_pristine_frames.append(frame)\n\nrefined_defect_frames = []\nfor frame in frames_defect:\n    neighs = (frame.get_all_distances(mic=True) < cur_cutoff).sum(axis=0) - 1\n    num_defects = (neighs > 4).sum() + (neighs < 4).sum()\n    if num_defects > 4:\n        refined_defect_frames.append(frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute SOAP descriptors using featomic\n\nNow, we move on and compute the SOAP descriptors for the refined\nstructures. First, define the featomic hyperparameters used to\ncompute SOAP. Among the hypers, notice that the cutoff is chosen\nto be 2.85 \u00c5, and the radial scaling is turned off. These were\nheuristic choices made to accentuate the difference in the LPR\nbased on the nearest-neighbor coordination. (Do not blindly\nuse this set of hypers for production-quality model training!)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Hypers dictionary\nhypers = {\n    \"cutoff\": {\"radius\": 2.85, \"smoothing\": {\"type\": \"ShiftedCosine\", \"width\": 0.1}},\n    \"density\": {\"type\": \"Gaussian\", \"width\": 0.5},\n    \"basis\": {\n        \"type\": \"TensorProduct\",\n        \"max_angular\": 12,\n        \"radial\": {\"type\": \"Gto\", \"max_radial\": 9},\n        \"spline_accuracy\": 1e-08,\n    },\n}\n# Define featomic calculator\ncalculator = SoapPowerSpectrum(**hypers)\n\n# Calculate the SOAP power spectrum\nXlist_pristine = []\nfor frame in refined_pristine_frames:\n    descriptor = calculator.compute(frame)\n    Xlist_pristine.append(np.array(descriptor.block().values))\n\nXlist_defect = []\nfor frame in refined_defect_frames:\n    descriptor = calculator.compute(frame)\n    Xlist_defect.append(np.array(descriptor.block().values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Organize structures into \"training\" and \"test\" sets\n\nNow we move on and compute the SOAP descriptors for the refined\nstructures. First, define the featomic hyperparameters used to\ncompute SOAP.\n\nNotice that the format in which we handle the descriptors is as a\nlist of :code:`np.array` descriptor blocks. This is to ensure\ncompatibility with how things have been implemented in the LPR\nmodule of :code:`scikit-matter`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_train = 400\nn_add = 50\nn_test = 50\n\nX_pristine = [Xlist for Xlist in Xlist_pristine[: n_train + n_add]]\nX_defect = [Xlist for Xlist in Xlist_defect[:n_add]]\nX_test = [Xlist for Xlist in Xlist_defect[n_add : n_add + n_test]]\n\n# Save coordination values for visualization\ntest_coord = []\nfor frame in refined_defect_frames[n_add : n_add + n_test]:\n    coord = (frame.get_all_distances(mic=True) < cur_cutoff - 0.05).sum(axis=0) - 1\n    test_coord += coord.tolist()\ntest_coord = np.array(test_coord)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the LPR for the test set\n\nNext, we will use the :code:`local_prediction_rigidity` module of\n[scikit-matter](https://scikit-matter.readthedocs.io/en/latest/)\nto compute the LPRs for the test set that we have set apart.\n\nLPR reflects how the ML model perceives a local environment,\ngiven a collection of other structures, similar or different.\nIt should then carry over some of the details involved in training\nthe model, in this case the regularization strength.\n\nFor this example, we have foregone on the actual model training,\nand so we define an arbitrary value for the alpha.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alpha = 1e-4\nLPR_test, rank = lpr(X_pristine, X_test, alpha)\nLPR_test = np.hstack(LPR_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the LPR on a PCA map\n\nWe now visualize the LPRs of the test set on a PCA map,\nwhere the PCA is performed on the SOAP descriptors of\ndefect-containing dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=5)\ndescriptors_all = calculator.compute(refined_defect_frames)\npca.fit_transform(descriptors_all.block().values)\nPCA_test = pca.transform(np.vstack(X_test))\n\nrmin = np.log10(LPR_test.min()) + 0.5\nrmax = np.log10(LPR_test.max()) - 0.5\n\nfig = plt.figure(figsize=(5, 4), dpi=200)\nax = fig.add_subplot()\nim = ax.scatter(\n    PCA_test[:, 0],\n    PCA_test[:, 1],\n    c=LPR_test,\n    s=20,\n    linewidths=0,\n    norm=LogNorm(vmin=10**rmin, vmax=10**rmax),\n    cmap=\"viridis\",\n)\n\nax.set_xlabel(\"PC1\")\nax.set_ylabel(\"PC2\")\nfig.colorbar(im, ax=ax, label=\"LPR\")\nax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the PCA map, where each point corresponds to an\natomic environment of the test set structures, one\ncan observe 4 different clusters of points, arranged\nalong PC1. This corresponds to the coordination numbers\nranging from 3 to 6. Since the training set contains\nstructures exclusively composed of 4-coordinated atoms,\nLPR is distinctly high for the second, main cluster of\npoints, and quite low for the three other clusters.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Studying the LPR after dataset modification\n\nWe now want to see what would happen when defect structures\nare included into the training set of the model. For this,\nwe first create a modified dataset that incorporates in the\ndefect structures, and recompute the LPR.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_new = X_pristine[:n_train] + X_defect[:n_add]\nLPR_test_new, rank = lpr(X_new, X_test, alpha)\nLPR_test_new = np.hstack(LPR_test_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then visualize the change in the LPR with the\nmodification of the dataset by plotting the same PCA\nmap, but now colored by the ratio of new set of LPR\nvalues (after dataset modification) over the original\none.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5, 4), dpi=200)\nax = fig.add_subplot()\nim = ax.scatter(\n    PCA_test[:, 0],\n    PCA_test[:, 1],\n    c=LPR_test_new / LPR_test,\n    s=20,\n    linewidths=0,\n    # norm=LogNorm(vmin=10**rmin, vmax=10**rmax),\n    cmap=\"OrRd\",\n)\nax.set_xlabel(\"PC1\")\nax.set_ylabel(\"PC2\")\nfig.colorbar(im, ax=ax, label=r\"LPR$_{\\mathrm{new}}$ / LPR$_{\\mathrm{old}}$\")\nax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is apparent that while the LPR stays more or less consistent for the\n4-coordinated atoms, it is significantly enhanced for the defective environments\nas a result of the inclusion of defective structures in the training set.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}