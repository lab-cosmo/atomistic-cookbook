{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Periodic Hamiltonian learning\n\n:Authors: Paolo Pegolo [@ppegolo](https://github.com/ppegolo)_,\n          Jigyasa Nigam [@curiosity54](https://github.com/curiosity54)_\n\nThis tutorial explains how to train a machine learning model for the\nelectronic Hamiltonian of a periodic system. Even though we focus on\nperiodic systems, the code and techniques presented here can be directly\ntransferred to molecules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, import the necessary packages\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport warnings\nimport zipfile\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport requests\nimport torch\nfrom matplotlib.animation import FuncAnimation\nfrom mlelec.data.qmdataset import QMDataset\nfrom mlelec.utils.pbc_utils import blocks_to_matrix\nfrom mlelec.utils.plot_utils import plot_bands_frame\n\n\nos.environ[\"PYSCFAD_BACKEND\"] = \"torch\"\nfrom mlelec.data.derived_properties import compute_eigenvalues  # noqa: E402\nfrom mlelec.data.mldataset import MLDataset  # noqa: E402\nfrom mlelec.models.equivariant_lightning import (  # noqa: E402\n    LitEquivariantModel,\n    MSELoss,\n)\n\n\nwarnings.filterwarnings(\"ignore\")\ntorch.set_default_dtype(torch.float64)\n\n# sphinx_gallery_thumbnail_number = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Data and Prepare Data Set\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data set contains 35 distorted graphene unit cells containing 2\natoms. The reference density functional theory (DFT) calculations are\nperformed with [CP2K](https://www.cp2k.org/)_ using a minimal\n[STO-3G](https://en.wikipedia.org/wiki/STO-nG_basis_sets)_ basis and\nthe [PBE](https://doi.org/10.1103/PhysRevLett.77.3865)_ functional.\nThe Kohn-Sham equations are solved on a Monkhorst-Pack grid of\n$15\\times 15\\times 1$ points in the Brillouin zone of the crystal.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Obtain structures and DFT data\n\nGenerating training structures requires running a suitable DFT code,\nand converting the output data in a format that can be processed by\nthe ML library ``mlelec``. Given that it takes some time to run even\nthese small calculations, we provide pre-computed data, but you can\nalso find instructions on how to generate data from scratch.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run your own cp2k calculations\n\nIf you have computational resources, you can run the DFT calculations\nneeded to produce the data set. [This other\ntutorial](https://tinyurl.com/cp2krun)_ in the atomistic cookbook can\nhelp you set up the CP2K calculations for this data set, using the\n``reftraj_hamiltonian.cp2k`` file provided in ``data/``. To do the same\nfor another data set, adapt the reftraj file.\nWe will provide here some of the functions in the [batch-cp2k\ntutorial](https://tinyurl.com/cp2krun)_ that need to be adapted to the\ncurrent data set. Note however you will have to modify these and combine\nthem with other tutorials to actually generate the data.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start by importing all the modules from the [batch-cp2k\ntutorial](https://tinyurl.com/cp2krun)_ and run the cell to install\nCP2K. Run also the cells up to the one defining ``write_cp2k_in``.\nThe following code snippet defines a slighly modified version of that function,\nallowing for non-orthorombic supercell, and accounting for the reftraj file\nname change.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   def write_cp2k_in(\n       fname: str,\n       project_name: str,\n       last_snapshot: int,\n       cell_a: List[float],\n       cell_b: List[float],\n       cell_c: List[float],\n   ) -> None:\n       \"\"\"Writes a cp2k input file from a template.\n\n       Importantly, it writes the location of the basis set definitions,\n       determined from the path of the system CP2K install to the input file.\n       \"\"\"\n\n       cp2k_in = open(\"reftraj_hamiltonian.cp2k\", \"r\").read()\n\n       cp2k_in = cp2k_in.replace(\"//PROJECT//\", project_name)\n       cp2k_in = cp2k_in.replace(\"//LAST_SNAPSHOT//\", str(last_snapshot))\n       cp2k_in = cp2k_in.replace(\"//CELL_A//\", \" \".join([f\"{c:.6f}\" for c in cell_a]))\n       cp2k_in = cp2k_in.replace(\"//CELL_B//\", \" \".join([f\"{c:.6f}\" for c in cell_b]))\n       cp2k_in = cp2k_in.replace(\"//CELL_C//\", \" \".join([f\"{c:.6f}\" for c in cell_c]))\n\n       with open(fname, \"w\") as f:\n           f.write(cp2k_in)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unlike the [batch-cp2k tutorial](https://tinyurl.com/cp2krun)_, the\ncurrent data set includes a single stoichiometry, $\\mathrm{C_2}$.\nTherefore, you can run this cell to set the calculation scripts up.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   project_name = 'graphene'\n   frames = ase_read('C2.xyz', index=':')\n   os.makedirs(project_name, exist_ok=True)\n   os.makedirs(f\"{project_name}/FOCK\", exist_ok=True)\n   os.makedirs(f\"{project_name}/OVER\", exist_ok=True)\n\n   write_cp2k_in(\n           f\"{project_name}/in.cp2k\",\n           project_name=project_name,\n           last_snapshot=len(frames),\n           cell_a=frames[0].cell.array[0],\n           cell_b=frames[0].cell.array[1],\n           cell_c=frames[0].cell.array[2],\n       )\n\n   ase_write(f\"{project_name}/init.xyz\", frames[0])\n   write_reftraj(f\"{project_name}/reftraj.xyz\", frames)\n   write_cellfile(f\"{project_name}/reftraj.cell\", frames)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The CP2K calculations can be simply run using:\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   subprocess.run((\n       f\"cp2k.ssmp -i {project_name}/in.cp2k \"\n       \"> {project_name}/out.cp2k\"\n       ),\n       shell=True)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the calculations are done, we can parse the results with:\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   from scipy.sparse import csr_matrix\n\n   nao = 10\n   ifr = 1\n   fock = []\n   over = []\n   with open(f\"{project_name}/out.cp2k\", \"r\") as outfile:\n       T_lists = []  # List to hold all T_list instances\n       while True:\n           line = outfile.readline()\n           if not line:\n               break\n           if line.strip().split()[:3] != [\"KS\", \"CSR\", \"write|\"]:\n               continue\n           else:\n               nT = int(line.strip().split()[3])\n               outfile.readline()  # Skip the next line if necessary\n               T_list = []  # Initialize a new T_list for this block\n               for _ in range(nT):\n                   line = outfile.readline()\n                   if not line:\n                       break\n                   T_list.append([np.int32(j) for j in line.strip().split()[1:4]])\n               T_list = np.array(T_list)\n               T_lists.append(T_list)  # Append the T_list to T_lists\n               fock_ = {}\n               over_ = {}\n               for iT, T in enumerate(\n                   T_list\n               ):  # Loop through the translations and load matrices\n                   T = T.tolist()\n                   r, c, data = np.loadtxt(\n                       (\n                           f\"{project_name}/FOCK/{project_name}\"\n                           f\"-KS_SPIN_1_R_{iT+1}-1_{ifr}.csr\"\n                       ),\n                       unpack=True,\n                   )\n                   r = np.int32(r - 1)\n                   c = np.int32(c - 1)\n                   fock_[tuple(T)] = csr_matrix(\n                       (data, (r, c)), shape=(nao, nao)\n                   ).toarray()\n\n                   r, c, data = np.loadtxt(\n                       (\n                           f\"{project_name}/OVER/{project_name}\"\n                           f\"-S_SPIN_1_R_{iT+1}-1_{ifr}.csr\"\n                       ),\n                       unpack=True,\n                   )\n                   r = np.int32(r - 1)\n                   c = np.int32(c - 1)\n                   over_[tuple(T)] = csr_matrix(\n                       (data, (r, c)), shape=(nao, nao)\n                   ).toarray()\n               fock.append(fock_)\n               over.append(over_)\n               ifr += 1\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now save the matrices to ``.npy`` files, and a file with the\nk-grids used in the calculations.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   os.makedirs(\"data\", exist_ok=True)\n   # Save the Hamiltonians\n   np.save(\"data/graphene_fock.npy\", fock)\n   # Save the overlaps\n   np.save(\"data/graphene_ovlp.npy\", over)\n   # Write a file with the k-grids, one line per structure\n   np.savetxt('data/kmesh.dat', [[15,15,1]]*len(frames), fmt='%d')\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Download precomputed data\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the sake of simplicity, you can also download precomputed data and\nrun just the machine learning part of the notebook using these data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "filename = \"precomputed.zip\"\nif not os.path.exists(filename):\n    url = (\n        \"https://github.com/curiosity54/mlelec/raw/\"\n        \"tutorial_periodic/examples/periodic_tutorial/precomputed.zip\"\n    )\n    response = requests.get(url)\n    response.raise_for_status()\n    with open(filename, \"wb\") as f:\n        f.write(response.content)\n\nwith zipfile.ZipFile(filename, \"r\") as zip_ref:\n    zip_ref.extractall(\"./\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Periodic Hamiltonians in real and reciprocal space\n\nThe DFT calculations for the dataset above were performed using a\n*minimal* STO-3G basis. The basis set is specified for each species\nusing three quantum numbers, $n$, $l$, $m$. $n$\nis usually a natural number relating to the *radial* extent or\nresolution whereas $l$ and $m$ specify the *angular\ncomponents* determining the shape of the orbital and its orientation in\nspace. For example, $1s$ orbitals correspond to $n=1$,\n$l=0$ and $m=0$, while a $2p_z$ orbital corresponds to\n$n=2$, $l=1$ and $m=0$. For the STO-3G basis-set,\nthese quantum numbers for Carbon (identified by its atomic number) are\ngiven as follows.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "basis = \"sto-3g\"\norbitals = {\n    \"sto-3g\": {6: [[1, 0, 0], [2, 0, 0], [2, 1, -1], [2, 1, 0], [2, 1, 1]]},\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each *frame* which of either train and test structures, the QM data\ncomprises the configuration, along with the corresponding *overlap* and\n*Hamiltonian* (used interchangeably with *Fock*) matrices in the basis\nspecified above, as well as the $k$-point grid that was used for the\ncalculation.\n\nNote that we are currently specifying these matrices in *real-space*,\n$\\mathbf{H}(\\mathbf{t})$ , such that the element\n$\\langle \\mathbf{0} i nlm| \\hat{H}| \\mathbf{t} i' n'l'm'\\rangle$\nindicates the interaction between orbital $nlm$ on atom $i$\nin the undisplaced cell (denoted by the null lattice translation,\n$\\mathbf{t}=\\mathbf{0}$) and orbital $n'l'm'$ on atom\n$i'$ in a periodic copy of the unit cell translated by\n$\\mathbf{t}$. A short-hand notation for\n$\\langle \\mathbf{0} i nlm| \\hat{H}| \\mathbf{t} i' n'l'm'\\rangle$\nis $H_{\\small\\substack{i,nlm\\\\i',n'l'm'}}(\\mathbf{t})$\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. figure:: graphene_lattice.png\n   :alt: Representation of a graphene unit cell and some replicas.\n   :width: 600px\n\n   Representation of a graphene unit cell and its\n   $3 \\times 3 \\times 1$ replicas in real space. The central cell\n   is denoted by $\\mathbf{t}=(0,0,0)$, while the cells translated\n   by a single lattice vector along directions 1 and 2 are denoted by\n   $\\mathbf{t}=(1,0,0)$ and $\\mathbf{t}=(0,1,0)$,\n   respectively. The Hamiltonian matrix element between the $1s$\n   orbital on atom $i$ in the central unit cell and the\n   $2p_z$ orbital on atom $i'$ in the\n   $\\mathbf{t}=(1,0,0)$ cell is schematically represented.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, we can provide the matrices in *reciprocal* (or\nFourier, $k$) space. These are related to the real-space matrices\nby a *Bloch sum*,\n\n\\begin{align}\\mathbf{H}(\\mathbf{k})=\\sum_{\\mathbf{t}}\\\n  e^{i\\mathbf{k}\\cdot\\mathbf{t}} \\mathbf{H}(\\mathbf{t}).\\end{align}\n\n\nIn the case the input matrices are in reciprocal space, there should be\none matrix per $k$-point in the grid.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### A ``QMDataset`` to store the DFT data\nThe ``QMDataset`` class holds all the relevant data\nobtained from a quantum-mechanical (in this case, DFT) calculation,\ncombining information from the files containing structures,\nHamiltonians and overlap matrices, and $k$-point mesh.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "qmdata = QMDataset.from_file(\n    # File containing the atomistic structures\n    frames_path=\"data/C2.xyz\",\n    # File containing the Hamiltonian (of Fock) matrices\n    fock_realspace_path=\"graphene_fock.npy\",\n    # File containing the overlap matrices\n    overlap_realspace_path=\"graphene_ovlp.npy\",\n    # File containing the k-point grids used for the DFT calculations\n    kmesh_path=\"kmesh.dat\",\n    # Physical dimensionality of the system. Graphene is a 2D material\n    dimension=2,\n    # Device where to run the calculations\n    # (can be 'cpu' or 'cuda', if GPUs are available)\n    device=\"cpu\",\n    # Name of the basis set used for the calculations\n    orbs_name=basis,\n    # List of quantum numbers associated with the basis set orbitals\n    orbs=orbitals[basis],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantities stored in ``QMDataset`` can be accessed as attributes,\ne.g.\u00a0``qmdata.fock_realspace`` is a list (one element per structure) of\ndictionaries labeled by the indices of the unit cell real-space\ntranslations containing ``torch.Tensor``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "structure_idx = 0\nrealspace_translation = 0, 0, 0\nprint(f\"The real-space Hamiltonian matrix for structure {structure_idx} labeled by\")\nprint(f\"translation T={realspace_translation} is:\")\nprint(f\"{qmdata.fock_realspace[structure_idx][realspace_translation]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Machine learning data set\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Symmetries of the Hamiltonian matrix\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data stored in ``QMDataset`` can be transformed into a format that\nis optimal for machine learning modeling by leveraging the underlying\n*physical symmetries* that characterize the atomistic structure, the\nbasis set, and their associated matrices.\n\nThe Hamiltonian matrix is a complex learning target, indexed by two\natoms and the orbitals centered on them. Each\n$\\mathbf{H}(\\mathbf{k})$ is a *Hermitian* matrix, while in real\nspace, periodicity introduces a *symmetry over translation pairs* such\nthat $\\mathbf{H}(-\\mathbf{t}) = \\mathbf{H}(\\mathbf{t})^\\dagger$,\nwhere the dagger, $\\dagger$, denotes Hermitian conjugation.\n\nTo address the symmetries associated with swapping atomic indices or\norbital labels, we divide the matrix into *blocks labeled by pairs of\natom types*.\n\n-  ``block_type = 0``, or *on-site* blocks, consist of elements\n   corresponding to the interaction of orbitals on the same atom,\n   $i = i'$.\n\n-  ``block_type = 2``, or *cross-species* blocks, consist of elements\n   corresponding to orbitals centered on atoms of distinct species.\n   Since the two atoms can be distinguished, they can be consistently\n   arranged in a predetermined order.\n\n-  ``block_type = 1, -1``, or *same-species* blocks, consist of\n   elements corresponding to orbitals centered on distinct atoms of the\n   same species. As these atoms are indistinguishable and cannot be\n   ordered definitively, the pair must be symmetrized for permutations.\n   We construct symmetric and antisymmetric combinations\n   $(\\mathbf{H}_{\\small\\substack{i,nlm\\\\i',n'l'm'}}(\\mathbf{t})\\pm\\\n   \\mathbf{H}_{\\small\\substack{i',nlm\\\\i,n'l'm'}}(\\mathbf{-t}))$\n   that correspond to ``block_type`` $+1$ and $-1$,\n   respectively.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Equivariant structure of the Hamiltonians\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even though the Hamiltonian operator under consideration is invariant,\n*its representation transforms under the action of structural rotations\nand inversions* due to the choice of the basis functions. Each of the\nblocks has elements of the form\n$\\langle\\mathbf{0}inlm|\\hat{H}|\\mathbf{t}i'n'l'm'\\rangle$, which\nare in an *uncoupled* representation and transform as a product of\n(real) spherical harmonics, $Y_l^m \\otimes Y_{l'}^{m'}$.\n\nThis product can be decomposed into a direct sum of irreducible\nrepresentations (irreps) of $\\mathrm{SO(3)}$,\n\n\\begin{align}\\lambda \\mu:\\lambda \\in [|l_1-l_2|,l_1+l_2],\\mu \\in [-\\lambda,\\lambda],\\end{align}\n\nwhich express the Hamiltonian blocks in terms of contributions that\nrotate independently and can be modeled using a feature that\ngeometrically describes the pair of atoms under consideration and shares\nthe same symmetry. We use the notation\n$H_{ii';nn'll'}^{\\lambda\\mu}$ to indicate the elements of the\nHamiltonian in this coupled basis.\n\nThe resulting irreps form a *coupled* representation, each of which\ntransforms as a spherical harmonic $Y^\\mu_\\lambda$ under\n$\\mathrm{SO(3)}$ rotations, but may exhibit more complex behavior\nunder inversions. For example, spherical harmonics transform under\ninversion, $\\hat{i}$, as polar tensors:\n\n\\begin{align}\\hat{i}Y^\\mu_\\lambda = (-1)^\\lambda Y^\\mu_\\lambda.\\end{align}\n\nSome of the coupled basis terms transform like $Y^\\mu_\\lambda$,\nwhile others instead transform as pseudotensors,\n\n\\begin{align}\\hat{i}H^{\\lambda\\mu}=(-1)^{\\lambda+1}H^{\\lambda\\mu}\\end{align}\n\nwhere we omit for simplicity the indices that are not directly associated\nwith inversion and rotation symmetry. For more details about the block\ndecomposition, please refer to [Nigam et al., J. Chem. Phys. 156, 014115\n(2022)](https://pubs.aip.org/aip/jcp/article/156/1/014115/2839817)_.\n\nThe following is an animation of a trajectory along a [Lissajous\ncurve](https://en.wikipedia.org/wiki/Lissajous_curve)_ in 3D space,\nalongside a colormap representing the values of the real-space\nHamiltonian matrix elements of the graphene unit cell in a minimal\nSTO-3G basis. From the animation, it is evident how invariant elements,\nsuch as those associated with interactions between $s$ orbitals,\ndo not change under structural rotations. On the other hand,\ninteractions allowing for equivariant components, such as the\n$s$-$p$ block, change under rotations.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "image_files = sorted(\n    [\n        f\"frames/{f}\"\n        for f in os.listdir(\"./frames\")\n        if f.startswith(\"rot_\") and f.endswith(\".png\")\n    ]\n)\nimages = [mpimg.imread(img) for img in image_files]\nfig, ax = plt.subplots()\nimg_display = ax.imshow(images[0])\nax.axis(\"off\")\n\n\ndef update(frame):\n    img_display.set_data(images[frame])\n    return [img_display]\n\n\nani = FuncAnimation(fig, update, frames=len(images), interval=20, blit=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   from IPython.display import HTML\n   HTML(ani.to_jshtml())\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Mapping geometric features to Hamiltonian targets\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each Hamiltonian block obtained from the procedure [described\nabove](#symmetries-of-the-hamiltonian-matrix)_ can be modeled using\nsymmetrized features.\n\nElements of ``block_type=0`` are indexed by a single atom and are best\ndescribed by a symmetrized atom-centered density correlation\n([ACDC](https://doi.org/10.1063/1.5090481)_), denoted by\n$|\\overline{\\rho_{i}^{\\otimes \\nu}; \\sigma; \\lambda\\mu }\\rangle$,\nwhere $\\nu$ refers to the correlation (body)-order, and\u2014just as\nfor the blocks\u2014$\\lambda \\mu$ indicate the $\\mathrm{SO(3)}$\nirrep to which the feature is symmetrized. The symbol $\\sigma$\ndenotes the inversion parity.\n\nFor other blocks, such as ``block_type=2``, which explicitly reference\ntwo atoms, we use [two-center](https://doi.org/10.1063/5.0072784)_\nACDCs, $|\\overline{\\rho_{ii'}^{\\otimes \\nu}; \\lambda\\mu }\\rangle$.\n\nFor ``block_type=1, -1``, we ensure equivariance with respect to atom\nindex permutation by constructing symmetric and antisymmetric pair\nfeatures:\n$(|\\overline{\\rho_{ii'}^{\\otimes \\nu};\\lambda\\mu }\\rangle\\pm\\\n|\\overline{\\rho_{i'i}^{\\otimes \\nu};\\lambda\\mu }\\rangle)$.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The features are discretized on a basis of radial functions and\nspherical harmonics, and their performance may depend on the\n*resolution* of the functions included in the model. There are\nadditional hyperparameters, such as the *cutoff* radius, which\ncontrols the extent of the atomic environment, and Gaussian widths. In\nthe following, we allow for flexibility in discretizing the\natom-centered and two-centered ACDCs by defining the hyperparameters for\nthe single-center (SC) $\\lambda$-SOAP and two-center (TC) ACDC\ndescriptors.\n\nThe single and two-center descriptors have very similar hyperparameters,\nexcept for the cutoff radius, which is larger for the two-center\ndescriptors to explicitly include distant pairs of atoms.\n\nNote that the descriptors of pairs of atoms separated by distances\ngreater than the cutoff radius are identically zero. Thus, any model\nbased on these descriptors would predict an identically zero value for\nthese pairs.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "SC_HYPERS = {\n    \"cutoff\": 3.0,\n    \"max_radial\": 6,\n    \"max_angular\": 6,\n    \"atomic_gaussian_width\": 0.5,\n    \"center_atom_weight\": 1,\n    \"radial_basis\": {\"Gto\": {}},\n    \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.5}},\n}\n\nTC_HYPERS = {\n    \"cutoff\": 6.0,\n    \"max_radial\": 6,\n    \"max_angular\": 6,\n    \"atomic_gaussian_width\": 0.3,\n    \"center_atom_weight\": 1.0,\n    \"radial_basis\": {\"Gto\": {}},\n    \"cutoff_function\": {\"ShiftedCosine\": {\"width\": 0.5}},\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then use the above defined hyperparameters to compute the descriptor\nand initialize a ``MLDataset`` instance, which contains, among other\nthings, the Hamiltonian block decomposition and the geometric features\ndescribed above.\n\nIn addition to computing the descriptors, ``MLDataset`` takes the data\nstored in the ``QMDataset`` instance and puts it in a form required to\ntrain a ML model.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ``item_names`` argument is a list of names of the quantities we want\nto compute and target in the ML model training, or that we want to be\nable to access later.\n\nFor example, ``fock_blocks`` is a\n[metatensor.Tensormap](https://tinyurl.com/tenmap)_ containing the\nHamiltonian coupled blocks. We also want to access the overlap matrices\nin $k$-space (``overlap_kspace``) to be able to compute the\nHamiltonian eigenvalues in the $k$-grid.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mldata = MLDataset(\n    # A QMDataset instance\n    qmdata,\n    # The names of the quantities to compute/initialize for the training\n    item_names=[\"fock_blocks\", \"overlap_kspace\"],\n    # Hypers for the SC descriptors\n    hypers_atom=SC_HYPERS,\n    # Hypers for the TC descriptors\n    hypers_pair=TC_HYPERS,\n    # Cutoff for the angular quantum number to use in the Clebsh-Gordan iterations\n    lcut=4,\n    # Fraction of structures in the training set\n    train_frac=0.7,\n    # Fraction of structures in the validation set\n    val_frac=0.2,\n    # Fraction of structures in the test set\n    test_frac=0.1,\n    # Whether to shuffle or not the structure indices before splitting the data set\n    shuffle=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The matrix decomposition into blocks and the calculations of geometric\nfeatures is performed by the ``MLDataset`` class.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``mldata.features`` is ``metatensor.TensorMap`` containing the\nstuctures\u2019 descriptors\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mldata.features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``mldata.items`` is a ``namedtuple`` containing the quantities defined\nin ``item_names``. e.g.\u00a0the coupled Hamiltonian blocks:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"The TensorMap containing the Hamiltonian coupled blocks is\")\nmldata.items.fock_blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Or the overlap matrices:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "structure_idx = 0\nk_idx = 0\nprint(f\"The overlap matrix for structure {structure_idx} at the {k_idx}-th k-point is\")\nmldata.items.overlap_kspace[structure_idx][k_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A machine learning model for the electronic Hamiltonian of graphene\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linear model\n\nIn simple cases, such as the present one, it is convenient to start with\na linear model that directly maps the geometric descriptors to the\ntarget coupled blocks. This can be achieved using [Ridge regression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Ridge.html)_\nas implemented in [scikit-learn](https://scikit-learn.org/stable/)_.\n\nThe linear regression model is expressed as\n\n\\begin{align}H_{ii',\\mathbf{Q}}^{\\lambda\\mu}(\\mathbf{t}) = \\\n   \\sum_\\mathbf{q} w_{\\mathbf{q}}^{\\mathbf{Q},\\lambda} \\\n   (\\rho_{ii'}^{\\otimes \\nu}(\\mathbf{t}))_{\\mathbf{q}}^{\\lambda\\mu},\\end{align}\n\nwhere a shorthand notation for the features has been introduced. Here,\n$\\mathbf{Q}$ includes all labels indicating the involved orbitals,\natomic species, and permutation symmetry, while $\\mathbf{q}$\nrepresents the feature dimension. The quantities\n$w_{\\mathbf{q}}^{\\mathbf{Q},\\lambda}$ are the model\u2019s weights.\nNote that different weights are associated with different values of\n$\\mathbf{Q}$ and $\\lambda$, but not with specific atom pairs\nor the translation vector, whose dependence arises only through the\ndescriptors.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In ``mlelec``, a linear model can be trained through the\n``LitEquivariantModel`` class, which accepts an ``init_from_ridge``\nkeyword. When set to ``True``, this initializes the weights of a more\ngeneral ``torch.nn.Module`` with the weights provided by Ridge\nregression.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will pass other keyword arguments to ``LitEquivariantModel``, to be\nable to further train the weights on top to the initial Ridge\nregression.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = LitEquivariantModel(\n    mldata=mldata,  # a MLDataset instance\n    nlayers=0,  # The number of hidden layers\n    nhidden=1,  # The number of neurons in each hidden layer\n    init_from_ridge=True,  # If True, initialize the weights and biases of the\n    # purely linear model from Ridge regression\n    optimizer=\"LBFGS\",  # Type of optimizer. Adam is likely better for\n    # a more general neural network\n    activation=\"SiLU\",  # The nonlinear activation function\n    learning_rate=1e-3,  # Initial learning rate (LR)\n    lr_scheduler_patience=10,\n    lr_scheduler_factor=0.7,\n    lr_scheduler_min_lr=1e-6,\n    loss_fn=MSELoss(),  # Use the mean square error as loss function\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model\u2019s accuracy in reproducing derived properties\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Hamiltonian coupled blocks predicted by the ML model can be accessed\nfrom ``model.forward()``\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predicted_blocks = model.forward(mldata.features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The real-space blocks can be transformed to Hamiltonian matrices via the\n``mlelec.utils.pbc_utils.blocks_to_matrix`` function. The resulting\nreal-space Hamiltonians can be Fourier transformed to give the\n$k$-space ones.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "HT = blocks_to_matrix(\n    predicted_blocks,\n    orbitals[\"sto-3g\"],\n    {A: qmdata.structures[A] for A in range(len(qmdata))},\n    detach=True,\n)\nHk = qmdata.bloch_sum(HT, is_tensor=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Kohn-Sham eigenvalues\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then compute the eigenvalues on the $k$-grid used for the\ncalculation to assess the model accuracy in predicting band energies.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "target_eigenvalues = compute_eigenvalues(qmdata.fock_kspace, qmdata.overlap_kspace)\npredicted_eigenvalues = compute_eigenvalues(Hk, qmdata.overlap_kspace)\n\nHartree = 27.211386024367243  # eV\n\nplt.rcParams[\"font.size\"] = 14\nfig, ax = plt.subplots()\nax.set_aspect(\"equal\")\n\nx_text = 0.38\ny_text = 0.2\nd = 0.06\n\nfor i, (idx, label) in enumerate(\n    zip(\n        [mldata.train_idx, mldata.val_idx, mldata.test_idx],\n        [\"train\", \"validation\", \"test\"],\n    )\n):\n\n    target = (\n        torch.stack([target_eigenvalues[i] for i in idx]).flatten().detach() * Hartree\n    )\n    prediction = (\n        torch.stack([predicted_eigenvalues[i] for i in idx]).flatten().detach()\n        * Hartree\n    )\n\n    non_core_states = target > -100\n    rmse = np.sqrt(\n        np.mean(\n            (target.numpy()[non_core_states] - prediction.numpy()[non_core_states]) ** 2\n        )\n    )\n    ax.scatter(target, prediction, marker=\".\", label=label, alpha=0.5)\n    ax.text(\n        x=x_text,\n        y=y_text - d * i,\n        s=rf\"$\\mathrm{{RMSE_{{{label}}}={rmse:.2f}\\,eV}}$\",\n        transform=ax.transAxes,\n    )\n\nxmin, xmax = ax.get_xlim()\nax.plot([xmin, xmax], [xmin, xmax], \"--k\")\nax.set_xlim(xmin, xmax)\nax.set_ylim(xmin, xmax)\nax.legend()\nax.set_xlabel(\"Target eigenvalues (eV)\")\nax.set_ylabel(\"Predicted eigenvalues (eV)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Graphene band structure\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apart from the eigenvalues on a mesh in the Brillouin zone, we can use\nthe real-space Hamiltonians predicted by the model to compute the band\nstructure along high-symmetry paths.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 4.8))\n\nidx = 0\n\nhandles = []\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n    # Plot reference\n    ax, h_ref = plot_bands_frame(\n        qmdata.fock_realspace[idx], idx, qmdata, ax=ax, color=\"blue\", lw=2\n    )\n\n    # Plot prediction\n    ax, h_pred = plot_bands_frame(\n        HT[idx], idx, qmdata, ax=ax, color=\"lime\", ls=\"--\", lw=2\n    )\n\nax.set_ylim(-30, 30)\nax.legend(\n    [h_ref, h_pred],\n    [\"Reference\", \"Prediction\"],\n    loc=\"center left\",\n    bbox_to_anchor=(1, 0.5),\n)\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding nonlinearities\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model used above consists of several submodels, one for each Hamiltonian\ncoupled block. Each submodel can be extended to a [multilayer\nperceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron)_\n(MLP) that maps the corresponding set of geometric features to the\nHamiltonian coupled block. Nonlinearities are applied to the invariants\nconstructed from each equivariant feature block using the\n``EquivariantNonlinearity`` module. This section outlines the process to\nmodify the model to introduce non-linear terms. Given that the time\nto train and evaluate the model would then increase, this section\nincludes snippets of code, but is not a complete implementation and\nis not executed when running this example.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The architecture of ``EquivariantNonlinearity`` can be visualized with\n``torchviz`` with the following snippet:\n\n.. code:: python\n\n   import torch\n   from mlelec.models.equivariant_model import EquivariantNonLinearity\n   from torchviz import make_dot\n   m = EquivariantNonLinearity(torch.nn.SiLU(), layersize = 10)\n   y = m.forward(torch.randn(3,3,10))\n   dot = make_dot(y, dict(m.named_parameters()))\n   dot.graph_attr.update(size='150,150')\n   dot.render(\"equivariantnonlinear\", format=\"png\")\n   dot\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. figure:: equivariantnonlinear.png\n   :alt: Graph representing the architecture of EquivariantNonLinearity\n   :width: 300px\n\n   Graph representing the architecture of EquivariantNonLinearity\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The global architecture of the MLP, implemented in ``simpleMLP``, can be\nvisualized with\n\n.. code:: python\n\n   import torch\n   from mlelec.models.equivariant_model import simpleMLP\n   from torchviz import make_dot\n   mlp = simpleMLP(\n       nin=10,\n       nout=1,\n       nhidden=1,\n       nlayers=1,\n       bias=True,\n       activation='SiLU',\n       apply_layer_norm=True\n       )\n   y = mlp.forward(torch.randn(1,1,10))\n   dot = make_dot(y, dict(mlp.named_parameters()))\n   dot.graph_attr.update(size='150,150')\n   dot.render(\"simpleMLP\", format=\"png\")\n   dot\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. figure:: simpleMLP.png\n   :alt: Graph representing the architecture of simpleMLP\n   :width: 600px\n\n   Graph representing the architecture of simpleMLP\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set up the training loop for stochastic gradient descent\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import additional modules needed to monitor the training.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   import lightning.pytorch as pl\n   from lightning.pytorch.callbacks import EarlyStopping\n   from mlelec.callbacks.logging import LoggingCallback\n   from mlelec.models.equivariant_lightning import MLDatasetDataModule\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set up a callback for logging training information such as the\ntraining and validation losses.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   logger_callback = LoggingCallback(log_every_n_epochs=5)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We set up an early stopping criterion to stop the training when the\nvalidation loss function stops decreasing.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   early_stopping = EarlyStopping(\n       monitor=\"val_loss\", min_delta=1e-3, patience=10, verbose=False, mode=\"min\"\n   )\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a ``lighting.pytorch.Trainer`` instance to handle the training\nloop. For example, we can further optimize the weights for 50 epochs using\nthe [LBFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS)_\noptimizer.\n\nNote that PyTorch Lightning requires the definition of a data module to\ninstantiate DataLoaders to be used during the training.\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   data_module = MLDatasetDataModule(mldata, batch_size=16, num_workers=0)\n\n   trainer = pl.Trainer(\n       max_epochs=50,\n       accelerator=\"cpu\",\n       check_val_every_n_epoch=10,\n       callbacks=[early_stopping, logger_callback],\n       logger=False,\n       enable_checkpointing=False,\n   )\n\n   trainer.fit(model, data_module)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We compute the test set loss to assess the model accuracy on an unseen\nset of structures\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. code:: python\n\n   trainer.test(model, data_module)\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this case, Ridge regression already provides good accuracy, so\nfurther optimizing the weights offers limited improvement. However, for\nmore complex datasets, the benefits of additional optimization can be\nsignificant.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}