{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Learning Capabilities with torchpme\n\n:Authors: Egor Rumiantsev [@E-Rum](https://github.com/E-Rum/); Philip Loche\n   [@PicoCentauri](https://github.com/PicoCentauri)\n\nThis example demonstrates the capabilities of the `torchpme` package, focusing on\nlearning target charges and utilizing the :class:`CombinedPotential` class to evaluate\npotentials that combine multiple pairwise interactions with optimizable ``weights``.\n\nThe ``weights`` are optimized to reproduce the energy of a system interacting purely\nthrough Coulomb forces.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport urllib.request\nfrom typing import Dict\n\nimport ase.io\nimport ase.visualize.plot\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torchpme import CombinedPotential, EwaldCalculator, InversePowerLawPotential\nfrom vesin import NeighborList"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Select computation device\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = \"cpu\"\n\nif torch.cuda.is_available():\n    device = \"cuda\"\n\ndtype = torch.float32\n\nprefactor = 0.5292  # Unit conversion prefactor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download and load the dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_dir = \"data\"\nos.makedirs(data_dir, exist_ok=True)\ndataset_url = \"https://archive.materialscloud.org/records/405an-d8183/files/point_charges_Training_set_p1.xyz\"  # noqa: E501\ndataset_path = os.path.join(data_dir, \"point_charges_Training_set.xyz\")\n\nif not os.path.isfile(dataset_path):\n    print(f\"Downloading dataset from {dataset_url} ...\")\n    urllib.request.urlretrieve(dataset_url, dataset_path)\n    print(\"Download complete.\")\n\n# The dataset consists of atomic configurations with reference energies.\nframes = ase.io.read(dataset_path, \":10\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define model parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cell = frames[0].get_cell().array\ncell_dimensions = np.linalg.norm(cell, axis=1)\ncutoff = np.min(cell_dimensions) / 2 - 1e-6  # Define the cutoff distance.\nsmearing = cutoff / 6.0  # Smearing parameter for interaction potentials.\nlr_wavelength = 0.5 * smearing  # Wavelength for long-range interactions.\n\nparams = {\"lr_wavelength\": lr_wavelength}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the neighbor list\nThe neighbor list is used to identify interacting pairs within the cutoff distance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "nl = NeighborList(cutoff=cutoff, full_list=False)\n\nl_positions = []\nl_cell = []\nl_neighbor_indices = []\nl_neighbor_distances = []\nl_ref_energy = torch.zeros(len(frames), device=device, dtype=dtype)\n\nfor i_atoms, atoms in enumerate(frames):\n    # Compute neighbor indices and distances\n    i, j, d = nl.compute(\n        points=atoms.positions, box=atoms.cell.array, periodic=True, quantities=\"ijd\"\n    )\n    i = torch.from_numpy(i.astype(int))\n    j = torch.from_numpy(j.astype(int))\n\n    # Store atom positions, cell information, neighbor indices, and distances\n    l_positions.append(torch.tensor(atoms.positions, device=device, dtype=dtype))\n    l_cell.append(torch.tensor(atoms.cell.array, device=device, dtype=dtype))\n    l_neighbor_indices.append(torch.vstack([i, j]).to(device=device).T)\n    l_neighbor_distances.append(torch.from_numpy(d).to(device=device, dtype=dtype))\n\n    # Store reference energy\n    l_ref_energy[i_atoms] = torch.tensor(\n        atoms.get_potential_energy(), device=device, dtype=dtype\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to assign charges to atoms\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def assign_charges(atoms, charge_dict: Dict[str, torch.Tensor]) -> torch.Tensor:\n    \"\"\"Assign charges to atoms based on their chemical symbols.\"\"\"\n    chemical_symbols = np.array(atoms.get_chemical_symbols())\n    charges = torch.zeros(len(atoms), dtype=dtype, device=device)\n\n    for chemical_symbol, charge in charge_dict.items():\n        charges[chemical_symbols == chemical_symbol] = charge\n\n    return charges.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the energy computation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def compute_energy(charge_dict: Dict[str, torch.Tensor]) -> torch.Tensor:\n    \"\"\"Compute the total energy based on assigned charges and potentials.\"\"\"\n    energy = torch.zeros(len(frames), device=device, dtype=dtype)\n    for i_atoms, atoms in enumerate(frames):\n        charges = assign_charges(atoms, charge_dict)\n\n        potential = calculator(\n            charges=charges,\n            cell=l_cell[i_atoms],\n            positions=l_positions[i_atoms],\n            neighbor_indices=l_neighbor_indices[i_atoms],\n            neighbor_distances=l_neighbor_distances[i_atoms],\n        )\n        energy[i_atoms] = (charges * potential).sum()\n\n    return energy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the loss function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def loss(charge_dict: Dict[str, torch.Tensor]) -> torch.Tensor:\n    \"\"\"Calculate the loss as the mean squared error between computed and reference\n    energies.\"\"\"\n    energy = compute_energy(charge_dict)\n    mse = torch.sum((energy - l_ref_energy) ** 2)\n\n    return mse.sum()  # Optionally add charge_penalty for strict neutrality enforcement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit charge model\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set initial values for the potential\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "potential = CombinedPotential(\n    potentials=[\n        InversePowerLawPotential(exponent=1.0, smearing=smearing, prefactor=prefactor)\n    ],\n    smearing=smearing,\n)\ncalculator = EwaldCalculator(potential=potential, **params)\ncalculator.to(device=device, dtype=dtype)\n\nq_Na = torch.tensor(1e-5).to(device=device, dtype=dtype)\nq_Na.requires_grad = True\n\nq_Cl = -torch.tensor(1e-5 + 0.2).to(device=device, dtype=dtype)\nq_Cl.requires_grad = True\n\ncharge_dict = {\"Na\": q_Na, \"Cl\": q_Cl}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Learning loop:\noptimize charges to minimize the loss function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([q_Na, q_Cl], lr=0.1)\n\nq_Na_timeseries = []\nq_Cl_timeseries = []\nloss_timeseries = []\n\nfor step in range(1000):\n    optimizer.zero_grad()\n\n    charge_dict = {\"Na\": q_Na, \"Cl\": q_Cl}\n\n    loss_value = loss(charge_dict)\n    loss_value.backward()\n    optimizer.step()\n\n    if step % 10 == 0:\n        print(\n            f\"Step: {step:>5}, Loss: {loss_value.item():>5.2e}, \"\n            + \", \".join([f\"q_{k}: {v:>5.2f}\" for k, v in charge_dict.items()]),\n            end=\"\\r\",\n        )\n\n    loss_timeseries.append(float(loss_value.detach().cpu()))\n    q_Na_timeseries.append(float(q_Na.detach().cpu()))\n    q_Cl_timeseries.append(float(q_Cl.detach().cpu()))\n\n    if loss_value < 1e-10:\n        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit kernel model\nThe second phase involves optimizing the weights of the combined potential kernels.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set initial values for the kernel model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "potential = CombinedPotential(\n    [\n        InversePowerLawPotential(exponent=1.0, smearing=smearing, prefactor=prefactor),\n        InversePowerLawPotential(exponent=2.0, smearing=smearing, prefactor=prefactor),\n    ],\n    smearing=smearing,\n)\n\ncalculator = EwaldCalculator(potential=potential, **params)\ncalculator.to(device=device, dtype=dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kernel optimization loop:\noptimize kernel weights to minimize the loss function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(calculator.parameters(), lr=0.1)\n\nweights_timeseries = []\nloss_timeseries = []\n\nfor step in range(1000):\n    optimizer.zero_grad()\n\n    # Fix charges to their ideal values for this phase\n    loss_value = loss({\"Na\": 1.0, \"Cl\": -1.0})\n    loss_value.backward()\n    optimizer.step()\n\n    if step % 10 == 0:\n        print(\n            f\"Step: {step:>5}, Loss: {loss_value.item():>5.2e} \"\n            + \", \".join(\n                [\n                    f\"w_{i}: {float(v):>5.2f}\"\n                    for i, v in enumerate(\n                        calculator.potential.weights.detach().cpu().tolist()\n                    )\n                ]\n            ),\n            end=\"\\r\",\n        )\n\n    loss_timeseries.append(float(loss_value.detach().cpu()))\n    weights_timeseries.append(calculator.potential.weights.detach().cpu().tolist())\n\n    if loss_value < 1e-10:\n        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot results\nVisualize the learning process for charges and kernel weights.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "palette = [\n    \"#EE7733\",  # Orange\n    \"#0077BB\",  # Blue\n    \"#33BBEE\",  # Light Blue\n    \"#EE3377\",  # Pink\n    \"#CC3311\",  # Red\n    \"#009988\",  # Teal\n    \"#BBBBBB\",  # Grey\n    \"#000000\",  # Black\n]\n\n\ndef plot_results(fname=None, show_snapshot=True):\n    \"\"\"\n    Plot the learning process for charges and kernel weights.\n\n    Args:\n        fname (str): File name to save the plot. If None, the plot is not saved.\n        show_snapshot (bool): Whether to show a snapshot of the atomic configuration.\n    \"\"\"\n    fig, ax = plt.subplots(\n        2,\n        sharex=True,\n        layout=\"constrained\",\n        dpi=200,\n    )\n\n    if show_snapshot:\n        ax_in = fig.add_axes([0.12, 0.14, 0.27, 0.27])\n        ase.visualize.plot.plot_atoms(atoms, ax=ax_in, radii=0.75)\n        ax_in.set_axis_off()\n\n    # Plot charge learning\n    ax[0].plot(q_Na_timeseries, c=palette[0], label=r\"Na\")\n    ax[0].plot(np.array(q_Cl_timeseries), c=palette[1], label=r\"Cl\")\n\n    ax[0].set_ylim(-1.3, 1.3)\n    ax[0].axhline(1, ls=\"dotted\", c=palette[0])\n    ax[0].axhline(-1, ls=\"dotted\", c=palette[1])\n    ax[0].legend()\n    ax[0].set_ylabel(r\"Charge / e\")\n\n    # Plot kernel weight learning\n    ax[1].axhline(1, c=palette[2], ls=\"dotted\")\n    ax[1].axhline(0, c=palette[3], ls=\"dotted\")\n    weights_timeseries_array = np.array(weights_timeseries)\n    ax[1].plot(weights_timeseries_array[:, 0], label=\"p=1\", c=palette[2])\n    ax[1].plot(weights_timeseries_array[:, 1], label=\"p=2\", c=palette[3])\n\n    ax[1].set_ylim(-0.2, 1.2)\n    ax[1].legend()\n    ax[1].set_ylabel(\"Kernel weight\")\n\n    for a in ax:\n        a.set_xscale(\"log\")\n\n    ax[1].set_xlabel(\"Learning epoch\")\n\n    fig.align_labels()\n\n    if fname is not None:\n        fig.savefig(fname, transparent=True, bbox_inches=\"tight\")\n\n    plt.show()\n\n\n# Call the plot function to visualize results\nplot_results(show_snapshot=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}