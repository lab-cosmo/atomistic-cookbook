{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Equivariant linear model for polarizability\n\n:Authors: Paolo Pegolo [@ppegolo](https://github.com/ppegolo)\n\nIn this example, we demonstrate how to construct a [metatensor atomistic model](https://docs.metatensor.org/latest/atomistic) for the polarizability tensor\nof molecular systems. This example uses the ``featomic`` library to compute\nequivariant descriptors, and ``scikit-learn`` to train a linear regression model.\nThe model can then be used in an ASE calculator.\nYou could also have a look at\n[this recipe based on scalar/tensorial models](http://localhost:8000/examples/polarizability/polarizability.html),\nwhich provides an alternative approach for equivariant learning\nof tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Optional\n\nimport ase.io\nimport chemiscope\n\n# Simulation and visualization tools\nimport matplotlib.pyplot as plt\nimport metatensor.torch as mts\n\n# Model wrapping and execution tools\nimport numpy as np\nimport torch\nfrom featomic.torch import SphericalExpansion\nfrom featomic.torch.clebsch_gordan import (\n    EquivariantPowerSpectrum,\n    cartesian_to_spherical,\n)\nfrom metatensor.torch import Labels, TensorBlock, TensorMap\nfrom metatensor.torch.learn.nn import EquivariantLinear\nfrom metatomic.torch import (\n    AtomisticModel,\n    ModelCapabilities,\n    ModelEvaluationOptions,\n    ModelMetadata,\n    ModelOutput,\n    System,\n    load_atomistic_model,\n    systems_to_torch,\n)\nfrom metatomic.torch.ase_calculator import MetatomicCalculator\n\n# Core libraries\nfrom sklearn.linear_model import RidgeCV\n\n\ntorch.set_default_dtype(torch.float64)  # FIXME: This is a temporary fix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Polarizability tensor\nThe polarizability tensor describes the response of a molecule to an external electric\nfield.\n\n\\begin{align}\\alpha_{ij} = \\frac{\\partial^2 U}{\\partial E_i \\partial E_j}\\end{align}\n\nIt is a rank-2 symmetric tensor and it can be decomposed into irreducible\nspherical components. Due to its symmetry, only the components with $\\lambda=0$\nand $\\lambda=2$ are non-zero. The $\\lambda=0$ component is a scalar, while\nthe $\\lambda=2$ component corresponds to a symmetric traceless matrix\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the training data\nWe load a simple dataset of $\\mathrm{C}_5\\mathrm{NH}_7$ molecules and\ntheir polarizability tensors stored in extended XYZ format.\nWe also visualize the polarizability as ellipsoids to demonstrate the\nanisotropy of this molecular property.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ase_frames = ase.io.read(\"data/qm7x_reduced_100.xyz\", index=\":\")\n\nellipsoids = chemiscope.ase_tensors_to_ellipsoids(\n    ase_frames, \"polarizability\", scale=0.15\n)\nellipsoids[\"parameters\"][\"global\"][\"color\"] = \"#FF8800\"\ncs = chemiscope.show(\n    ase_frames,\n    shapes={\"alpha\": ellipsoids},\n    mode=\"structure\",\n    settings=chemiscope.quick_settings(\n        structure_settings={\"shape\": [\"alpha\"]}, trajectory=True\n    ),\n)\ncs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read the polarizability tensors and store them in a :class:`TensorMap`\nWe extract the polarizability tensors from the extended XYZ file and store them in a\n:class:`metatensor.torch.TensorMap`. The polarizability tensors are stored as\nCartesian tensors.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cartesian_polarizability = np.stack(\n    [frame.info[\"polarizability\"].reshape(3, 3) for frame in ase_frames]\n)\ncartesian_tensormap = TensorMap(\n    keys=Labels.single(),\n    blocks=[\n        TensorBlock(\n            samples=Labels.range(\"system\", len(ase_frames)),\n            components=[Labels.range(name, 3) for name in [\"xyz_1\", \"xyz_2\"]],\n            properties=Labels([\"polarizability\"], torch.tensor([[0]])),\n            values=torch.from_numpy(cartesian_polarizability).unsqueeze(-1),\n        )\n    ],\n)\n\nprint(cartesian_tensormap)\nprint(cartesian_tensormap.block(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also convert the Cartesian tensors to irreducible spherical\ntensors using the\n:func:`featomic.torch.clebsch_gordan.cartesian_to_spherical`\nfunction. Now the polarizability is stored in a\n:class:`metatensor.torch.TensorMap` object\nthat contains two :class:`metatensor.torch.TensorBlock` labeled by\nthe irreducible spherical components as keys.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spherical_tensormap = mts.remove_dimension(\n    cartesian_to_spherical(cartesian_tensormap, components=[\"xyz_1\", \"xyz_2\"]),\n    \"keys\",\n    \"_\",\n)\n\nprint(spherical_tensormap)\nprint(spherical_tensormap.block(0))\nprint(spherical_tensormap.block(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split the dataset\nThe dataset is split into training and test sets using a 80/20\nratio. We also visualize the polarizability as ellipsoids to e\ninto training and test sets according to the indices previously\ndefined.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_frames = len(ase_frames)\ntrain_idx = np.random.choice(n_frames, int(0.8 * n_frames), replace=False)\ntest_idx = np.setdiff1d(np.arange(n_frames), train_idx)\nspherical_tensormap_train = mts.slice(\n    spherical_tensormap,\n    \"samples\",\n    Labels(\"system\", torch.from_numpy(train_idx).reshape(-1, 1)),\n)\ncartesian_tensormap_test = mts.slice(\n    cartesian_tensormap,\n    \"samples\",\n    Labels(\"system\", torch.from_numpy(test_idx).reshape(-1, 1)),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Equivariant model for polarizability\nThe polarizability tensor can be predicted using equivariant linear models. In this\nexample, we use the ``featomic`` library to compute equivariant $\\lambda$-SOAP\ndescriptors, adapted to the symmetry of the irreducible components of\n$\\boldsymbol{\\alpha}$ and ``scikit-learn`` to train a symmetry-adapted\nlinear ridge regression model.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility functions\nWe define a couple of utility functions to convert the spherical polarizability tensor\nback to a Cartesian tensor.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first utility function takes the $\\lambda=2$ spherical components and\nreconstructs the $3 \\times 3$ symmetric traceless matrix.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def matrix_from_l2_components(l2: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Inverts the spherical projection function for a symmetric, traceless 3x3 tensor.\n\n    Given:\n        l2 : array-like of 5 components\n            These are the irreducible spherical components multiplied by sqrt(2),\n            i.e., l2 = sqrt(2) * [t0, t1, t2, t3, t4], where:\n                t0 = (A[0,1] + A[1,0])/2\n                t1 = (A[1,2] + A[2,1])/2\n                t2 = (2*A[2,2] - A[0,0] - A[1,1])/(2*sqrt(3))\n                t3 = (A[0,2] + A[2,0])/2\n                t4 = (A[0,0] - A[1,1])/2\n\n    Returns:\n        A : (3,3) numpy array\n            The symmetric, traceless matrix reconstructed from the components.\n    \"\"\"\n    # Recover the t_i by dividing by sqrt(2)\n    sqrt2 = torch.sqrt(torch.tensor(2.0, dtype=l2.dtype))\n    sqrt3 = torch.sqrt(torch.tensor(3.0, dtype=l2.dtype))\n    l2 = l2 / sqrt2\n\n    # Allocate the 3x3 matrix A\n    A = torch.empty((3, 3), dtype=l2.dtype)\n\n    # Diagonal entries:\n    # Use the traceless condition A[0,0] + A[1,1] + A[2,2] = 0.\n    # Also, from the definitions:\n    #   t4 = (A[0,0] - A[1,1]) / 2\n    #   t2 = (2*A[2,2] - A[0,0] - A[1,1])/(2*sqrt3)\n    #\n    # Solve for A[0,0] and A[1,1]:\n    A[0, 0] = -(sqrt3 * l2[2]) / 3 + l2[4]\n    A[1, 1] = -(sqrt3 * l2[2]) / 3 - l2[4]\n    A[2, 2] = (2 * sqrt3 * l2[2]) / 3  # Since A[2,2] = - (A[0,0] + A[1,1])\n\n    # Off-diagonals:\n    A[0, 1] = l2[0]\n    A[1, 0] = l2[0]\n\n    A[1, 2] = l2[1]\n    A[2, 1] = l2[1]\n\n    A[0, 2] = l2[3]\n    A[2, 0] = l2[3]\n\n    return A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The second utility function takes the spherical polarizability tensor and uses the\n``matrix_from_l2_components`` function to reconstruct symmetric traceless part of the\nCartesian tensor, and then combines it with the scalar part to reconstruct the full\nCartesian tensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def spherical_to_cartesian(spherical_tensor: TensorMap) -> TensorMap:\n\n    dtype = spherical_tensor[0].values.dtype\n\n    new_block: Dict[int, torch.Tensor] = {}\n\n    eye = torch.eye(3, dtype=dtype)\n    sqrt3 = torch.sqrt(torch.tensor(3.0, dtype=dtype))\n    block_0 = spherical_tensor[0]\n    block_2 = spherical_tensor[1]\n    system_ids = block_0.samples.values.flatten()\n\n    for i, A in enumerate(system_ids):\n        new_block[int(A)] = -block_0.values[\n            i\n        ].flatten() * eye / sqrt3 + matrix_from_l2_components(\n            block_2.values[i].squeeze()\n        )\n\n    return TensorMap(\n        keys=Labels([\"_\"], torch.tensor([[0]], dtype=torch.int32)),\n        blocks=[\n            TensorBlock(\n                samples=Labels(\n                    \"system\",\n                    torch.tensor(\n                        [k for k in new_block.keys()], dtype=torch.int32\n                    ).reshape(-1, 1),\n                ),\n                components=[\n                    Labels(\n                        \"xyz_1\",\n                        torch.tensor([0, 1, 2], dtype=torch.int32).reshape(-1, 1),\n                    ),\n                    Labels(\n                        \"xyz_2\",\n                        torch.tensor([0, 1, 2], dtype=torch.int32).reshape(-1, 1),\n                    ),\n                ],\n                properties=Labels([\"_\"], torch.tensor([[0]], dtype=torch.int32)),\n                values=torch.stack(\n                    [new_block[A] for A in new_block]\n                ).unsqueeze(  # .roll((-1, -1), dims=(1, 2))\n                    -1\n                ),\n            )\n        ],\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation of a ``torch`` module for polarizability\nIn order to implement a polarizability model compatible with ``metatomic``, we need to\nwe need to define a ``torch.nn.Module`` with a ``forward`` method that takes a list of\n:class:`metatomic.torch.System` and returns a dictionary of\n:class:`metatensor.torch.TensorMap` objects. The ``forward`` method must be compatible\nwith ``TorchScript``.\n\nHere, the :class:`PolarizabilityModel` class is defined. It takes as input a\n``SphericalExpansion`` object, a list of atomic types, and ``dtype``. The\n``forward`` method computes the descriptors and applies the linear model to predict\nthe polarizability tensor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class PolarizabilityModel(torch.nn.Module):\n    def __init__(\n        self,\n        spex_calculator: SphericalExpansion,\n        atomic_types: List[int],\n        dtype: torch.dtype = None,\n    ) -> None:\n\n        super().__init__()\n\n        if dtype is None:\n            dtype = torch.float64\n        self.dtype = dtype\n        device = torch.device(\"cpu\")\n\n        self.hypers = spex_calculator.parameters\n\n        # Check that the atomic types are unique\n        assert len(set(atomic_types)) == len(atomic_types)\n        self.atomic_types = atomic_types\n\n        # Define lambda soap calculator\n        self.lambda_soap_calculator = EquivariantPowerSpectrum(\n            spex_calculator, dtype=self.dtype\n        )\n        self.selected_keys = mts.Labels(\n            [\"o3_lambda\", \"o3_sigma\"], torch.tensor([[0, 1], [2, 1]])\n        )\n        self._compute_metadata()\n\n        # Define the linear model that wraps the ridge regression results\n        in_keys = self.metadata.keys\n        in_features = [block.values.shape[-1] for block in self.metadata]\n        out_features = [1 for _ in self.metadata]\n        out_properties = [mts.Labels.single() for _ in self.metadata]\n\n        self.linear_model = EquivariantLinear(\n            in_keys=in_keys,\n            in_features=in_features,\n            out_features=out_features,\n            out_properties=out_properties,\n            dtype=self.dtype,\n            device=device,\n        )\n\n    def fit(self, training_systems, training_targets, alphas=None):\n\n        lambda_soap = self._compute_descriptor(training_systems)\n\n        ridges: List[RidgeCV] = []\n        for k in lambda_soap.keys:\n            X = lambda_soap.block(k).values\n            y = training_targets.block(k).values\n            n_samples, n_components, n_properties = X.shape\n            X = X.reshape(n_samples * n_components, n_properties)\n            y = y.reshape(n_samples * n_components, -1)\n            ridge = RidgeCV(alphas=alphas, fit_intercept=int(k[\"o3_lambda\"]) == 0)\n            ridge.fit(X, y)\n            ridges.append(ridge)\n\n        self._apply_weights(ridges)\n\n    def _compute_metadata(self):\n        # Create dummy system to get the property dimension\n        dummy_system = systems_to_torch(\n            ase.Atoms(\n                numbers=self.atomic_types,\n                positions=[[i / 4, 0, 0] for i in range(len(self.atomic_types))],\n            )\n        )\n\n        self.metadata = self.lambda_soap_calculator.compute_metadata(\n            dummy_system, selected_keys=self.selected_keys, neighbors_to_properties=True\n        ).keys_to_samples(\"center_type\")\n\n    def _apply_weights(self, ridges: List[RidgeCV]) -> None:\n        with torch.no_grad():\n            for model, ridge in zip(self.linear_model.module_map, ridges):\n                model.weight.copy_(torch.tensor(ridge.coef_, dtype=self.dtype))\n                if model.bias is not None:\n                    model.bias.copy_(torch.tensor(ridge.intercept_, dtype=self.dtype))\n\n    def _compute_descriptor(self, systems: List[System]) -> TensorMap:\n        # Actually compute lambda-SOAP power spectrum\n        lambda_soap = self.lambda_soap_calculator(\n            systems,\n            selected_keys=self.selected_keys,\n            neighbors_to_properties=True,\n        )\n\n        # Move the `center_type` keys to the sample dimension\n        lambda_soap = lambda_soap.keys_to_samples(\"center_type\")\n\n        # Polarizability is a \"per-structure\" quantity. We don't need to keep\n        # `center_type` and `atom` in samples, as we only need to predict the\n        # polarizability of the whole structure.\n        # A simple way to do so, is summing the descriptors over the `center_type` and\n        # `atom` sample dimensions.\n        lambda_soap = mts.sum_over_samples(lambda_soap, [\"center_type\", \"atom\"])\n\n        return lambda_soap\n\n    def forward(\n        self,\n        systems: List[System],  # noqa\n        outputs: Dict[str, ModelOutput],  # noqa\n        selected_atoms: Optional[Labels] = None,  # noqa\n    ) -> Dict[str, TensorMap]:  # noqa\n\n        if list(outputs.keys()) != [\"cookbook::polarizability\"]:\n            raise ValueError(\n                f\"`outputs` keys ({', '.join(outputs.keys())}) contain unsupported \"\n                \"keys. Only 'cookbook::polarizability' is supported.\"\n            )\n\n        if outputs[\"cookbook::polarizability\"].per_atom:\n            raise NotImplementedError(\"per-atom polarizabilities are not supported.\")\n\n        # Compute the descriptors\n        lambda_soap = self._compute_descriptor(systems)\n\n        # Apply the linear model\n        prediction = self.linear_model(lambda_soap)\n        prediction = spherical_to_cartesian(prediction)\n        # fails at saving due to TorchScript\n        return {\"cookbook::polarizability\": prediction}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the polarizability model\nWe train the polarizability model using the training data. We need to define the\nhyperparameters for the :class:`featomic.torch.SphericalExpansion` calculator and the\natomic types in the dataset to initialize the module.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hypers = {\n    \"cutoff\": {\"radius\": 4.5, \"smoothing\": {\"type\": \"ShiftedCosine\", \"width\": 0.1}},\n    \"density\": {\"type\": \"Gaussian\", \"width\": 0.3},\n    \"basis\": {\n        \"type\": \"TensorProduct\",\n        \"max_angular\": 3,\n        \"radial\": {\"type\": \"Gto\", \"max_radial\": 3},\n    },\n}\natomic_types = np.unique(\n    np.concatenate([frame.numbers for frame in ase_frames])\n).tolist()\n\nspherical_expansion_calculator = SphericalExpansion(**hypers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert ASE frames to :class:`metatensor.atomistic.System` objects.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instantiate the polarizability model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = PolarizabilityModel(\n    spherical_expansion_calculator,\n    atomic_types,\n    dtype=torch.float64,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ridge regression is performed as with a ``scikit-learn``-style `fit` method, and\nthe resulting weights are then used to initialize a\n:class:`metatensor.learn.nn.EquivariantLinear` module.\nThe :func:`PolariabilityModel.fit` method takes the training systems in\n:class:`metatomic.torch.System` format and the training target\n:class:`metatensor.torch.TensorMap` as input. The `alphas` parameter is used to\nspecify the range of regularization parameters to be tested.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "systems_train = [\n    system.to(dtype=torch.float64)\n    for system in systems_to_torch([ase_frames[i] for i in train_idx])\n]\nalphas = np.logspace(-6, 6, 50)\n\nmodel.fit(systems_train, spherical_tensormap_train, alphas=alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate the model\nWe evaluate the model on the test set to check the performance of the model. The API\nrequires a dictionary of :class:`metatensor.torch.ModelOutput` objects that specify\nthe quantity and unit of the output, and whether it is a ``per_atom`` quantity or not.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "outputs = {\n    \"cookbook::polarizability\": ModelOutput(\n        quantity=\"polarizability\", unit=\"a.u.\", per_atom=False\n    )\n}\nsystems_test = [\n    system.to(dtype=torch.float64)\n    for system in systems_to_torch([ase_frames[i] for i in test_idx])\n]\nprediction_test = model(systems_test, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us plot the predicted polarizability tensor against the true polarizability tensor\nfor the test set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "true_polarizability = np.concatenate(\n    [\n        cartesian_tensormap_test.block(k).values.flatten().numpy()\n        for k in cartesian_tensormap_test.keys\n    ]\n)\npredicted_polarizability = np.concatenate(\n    [\n        prediction_test[\"cookbook::polarizability\"]\n        .block(k)\n        .values.flatten()\n        .detach()\n        .numpy()\n        for k in prediction_test[\"cookbook::polarizability\"].keys\n    ]\n)\n\nfig, ax = plt.subplots(1, 1, figsize=(4, 3), constrained_layout=True)\nax.set_aspect(\"equal\")\nax.plot(true_polarizability, predicted_polarizability, \".\")\nax.plot(\n    [true_polarizability.min(), true_polarizability.max()],\n    [true_polarizability.min(), true_polarizability.max()],\n    \"--k\",\n)\nax.set_xlabel(\"True polarizability (a.u.)\")\nax.set_ylabel(\"Predicted polarizability (a.u.)\")\nax.set_title(\"Polarizability prediction\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export the model as a metatomic model\nWrap the model in a\n:class:`metatomic.torch.AtomisticModel`\nobject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "outputs = {\n    \"cookbook::polarizability\": ModelOutput(\n        quantity=\"polarizability\", unit=\"a.u.\", per_atom=False\n    )\n}\n\noptions = ModelEvaluationOptions(\n    length_unit=\"angstrom\", outputs=outputs, selected_atoms=None\n)\n\nmodel_capabilities = ModelCapabilities(\n    outputs=outputs,\n    atomic_types=[1, 6, 7, 16],\n    interaction_range=4.5,\n    length_unit=\"angstrom\",\n    supported_devices=[\"cpu\"],\n    dtype=\"float64\",\n)\n\natomistic_model = AtomisticModel(model.eval(), ModelMetadata(), model_capabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model can be saved to disk using the\n:func:`metatomic.torch.save_atomistic_model` function.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "atomistic_model.save(\"polarizability_model.pt\", collect_extensions=\"extensions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Use the model as a metatensor calculator\nThe model can be used as a calculator with the\n:class:`metatomic.torch.MetatomicCalculator` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "atomistic_model = load_atomistic_model(\n    \"polarizability_model.pt\", extensions_directory=\"extensions\"\n)\nmta_calculator = MetatomicCalculator(atomistic_model)\n\nase_frames = ase.io.read(\"data/qm7x_reduced_100.xyz\", index=\":\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":class:`ase.Atoms` objects do not feature a :func:`get_polarizability` method that we\ncould call to compute the polarizability with our model. The easiest way to compute\nthe polarizability is then to directly use the :func:`MetatomicCalculator.run_model`\nmethod, which takes a list of :class:`ase.Atoms` objects and a dictionary of\n:class:`metatomic.torch.ModelOutput` objects as input. The output is a\ndictionary of :class:`metatensor.torch.TensorMap` objects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "computed_polarizabilities = []\nfor frame in ase_frames:\n    computed_polarizabilities.append(\n        mta_calculator.run_model(frame, outputs)[\"cookbook::polarizability\"]\n        .block(0)\n        .values.squeeze()\n        .numpy()\n    )\ncomputed_polarizabilities = np.stack(computed_polarizabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is essentially the same model as before, wrapped in a stand-alone format\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_mae = np.abs(\n    (cartesian_polarizability - computed_polarizabilities)[train_idx]\n).mean()\ntest_mae = np.abs(\n    (cartesian_polarizability - computed_polarizabilities)[test_idx]\n).mean()\n\nprint(\n    f\"\"\"\nModel train MAE: {train_mae} a.u.\nModel test MAE:  {test_mae} a.u.\n\"\"\"\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}